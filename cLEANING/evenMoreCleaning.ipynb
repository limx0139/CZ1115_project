{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chessdata = pd.read_csv('cleanedCleanedChessdata.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data is still absolutely massive, we split the dataset into bullet, blitz, rapid and classical, which are time formats, for which each player is allowed a set amount of time to play their moves. They represent, generally, 1 minute, 3 minute, 10 minute and 30 minute games respectively. We further split the data based ond on ranking, also remove the data on each players' clock, as it boils down to whether a game is forfeited on time, which is provided in another row, 'Termination' which has either Normal(checkmate) or time forfeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range (1,201):\n",
    "    chessdata=chessdata.drop(f'Clock_ply_{x}', axis=1)\n",
    "    chessdata=chessdata.drop(f'Eval_ply_{x}', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chessdata=chessdata.drop('Unnamed: 0.1',axis=1)\n",
    "chessdata=chessdata.drop('Unnamed: 0',axis=1)\n",
    "chessdata=chessdata.drop('Index.1',axis=1)\n",
    "chessdata=chessdata.drop('BlackRatingDiff',axis=1)\n",
    "chessdata=chessdata.drop('WhiteRatingDiff',axis=1)\n",
    "chessdata=chessdata.drop('Date',axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     197768\n",
       "unique       461\n",
       "top          A00\n",
       "freq        9112\n",
       "Name: ECO, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chessdata['ECO'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate average rating and rating difference as numeric predictors\n",
    "chessdata['ELO Diff'] = chessdata['WhiteElo'] - chessdata['BlackElo']\n",
    "chessdata['Ave ELO']=.5*(chessdata['WhiteElo'] +chessdata['BlackElo'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    197768.000000\n",
       "mean         -0.505714\n",
       "std         129.740981\n",
       "min       -1454.000000\n",
       "25%         -44.000000\n",
       "50%           0.000000\n",
       "75%          43.000000\n",
       "max        1406.000000\n",
       "Name: ELO Diff, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chessdata['ELO Diff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blitzData=chessdata.loc[chessdata['Category'] == 'Blitz']\n",
    "rapidData=chessdata.loc[chessdata['Category'] == 'Rapid']\n",
    "bulletData=chessdata.loc[chessdata['Category'] == 'Bullet']\n",
    "classicalData=chessdata.loc[chessdata['Category'] == 'Classical']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    197768.000000\n",
       "mean       1511.641170\n",
       "std         315.124362\n",
       "min         800.000000\n",
       "25%        1281.000000\n",
       "50%        1504.500000\n",
       "75%        1729.000000\n",
       "max        2960.000000\n",
       "Name: Ave ELO, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chessdata['Ave ELO'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use the above stats to construct our low, mid and high threshholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rinoa\\AppData\\Local\\Temp\\ipykernel_12844\\2906433793.py:1: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  blitzLowRatingData=blitzData[blitzData['Ave ELO'].between(0, 1300, inclusive=False)]\n",
      "C:\\Users\\rinoa\\AppData\\Local\\Temp\\ipykernel_12844\\2906433793.py:2: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  blitzMidRatingData=blitzData[blitzData['Ave ELO'].between(1300, 1700, inclusive=True)]\n",
      "C:\\Users\\rinoa\\AppData\\Local\\Temp\\ipykernel_12844\\2906433793.py:3: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  blitzHighRatingData=blitzData[blitzData['Ave ELO'].between(1700, 3500, inclusive=False)]\n",
      "C:\\Users\\rinoa\\AppData\\Local\\Temp\\ipykernel_12844\\2906433793.py:6: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  rapidLowRatingData=rapidData[rapidData['Ave ELO'].between(0, 1300, inclusive=False)]\n",
      "C:\\Users\\rinoa\\AppData\\Local\\Temp\\ipykernel_12844\\2906433793.py:7: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  rapidMidRatingData=rapidData[rapidData['Ave ELO'].between(1300, 1700, inclusive=True)]\n",
      "C:\\Users\\rinoa\\AppData\\Local\\Temp\\ipykernel_12844\\2906433793.py:8: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  rapidHighRatingData=rapidData[rapidData['Ave ELO'].between(1700, 3500, inclusive=False)]\n",
      "C:\\Users\\rinoa\\AppData\\Local\\Temp\\ipykernel_12844\\2906433793.py:11: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  bulletLowRatingData=bulletData[bulletData['Ave ELO'].between(0, 1300, inclusive=False)]\n",
      "C:\\Users\\rinoa\\AppData\\Local\\Temp\\ipykernel_12844\\2906433793.py:12: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  bulletMidRatingData=bulletData[bulletData['Ave ELO'].between(1300, 1700, inclusive=True)]\n",
      "C:\\Users\\rinoa\\AppData\\Local\\Temp\\ipykernel_12844\\2906433793.py:13: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  bulletHighRatingData=bulletData[bulletData['Ave ELO'].between(1700, 3500, inclusive=False)]\n",
      "C:\\Users\\rinoa\\AppData\\Local\\Temp\\ipykernel_12844\\2906433793.py:16: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  classicalLowRatingData=classicalData[classicalData['Ave ELO'].between(0, 1300, inclusive=False)]\n",
      "C:\\Users\\rinoa\\AppData\\Local\\Temp\\ipykernel_12844\\2906433793.py:17: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  classicalMidRatingData=classicalData[classicalData['Ave ELO'].between(1300, 1700, inclusive=True)]\n",
      "C:\\Users\\rinoa\\AppData\\Local\\Temp\\ipykernel_12844\\2906433793.py:18: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  classicalHighRatingData=classicalData[classicalData['Ave ELO'].between(1700, 3500, inclusive=False)]\n"
     ]
    }
   ],
   "source": [
    "blitzLowRatingData=blitzData[blitzData['Ave ELO'].between(0, 1300, inclusive=False)]\n",
    "blitzMidRatingData=blitzData[blitzData['Ave ELO'].between(1300, 1700, inclusive=True)]\n",
    "blitzHighRatingData=blitzData[blitzData['Ave ELO'].between(1700, 3500, inclusive=False)]\n",
    "\n",
    "\n",
    "rapidLowRatingData=rapidData[rapidData['Ave ELO'].between(0, 1300, inclusive=False)]\n",
    "rapidMidRatingData=rapidData[rapidData['Ave ELO'].between(1300, 1700, inclusive=True)]\n",
    "rapidHighRatingData=rapidData[rapidData['Ave ELO'].between(1700, 3500, inclusive=False)]\n",
    "\n",
    "\n",
    "bulletLowRatingData=bulletData[bulletData['Ave ELO'].between(0, 1300, inclusive=False)]\n",
    "bulletMidRatingData=bulletData[bulletData['Ave ELO'].between(1300, 1700, inclusive=True)]\n",
    "bulletHighRatingData=bulletData[bulletData['Ave ELO'].between(1700, 3500, inclusive=False)]\n",
    "\n",
    "\n",
    "classicalLowRatingData=classicalData[classicalData['Ave ELO'].between(0, 1300, inclusive=False)]\n",
    "classicalMidRatingData=classicalData[classicalData['Ave ELO'].between(1300, 1700, inclusive=True)]\n",
    "classicalHighRatingData=classicalData[classicalData['Ave ELO'].between(1700, 3500, inclusive=False)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, export the data which is finally ready to be worked on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blitzLowRatingData.to_csv('blitzLowRatingData.csv')\n",
    "blitzMidRatingData.to_csv('blitzMidRatingData.csv')\n",
    "blitzHighRatingData.to_csv('blitzHighingData.csv')\n",
    "\n",
    "bulletLowRatingData.to_csv('bulletLowRatingData.csv')\n",
    "bulletMidRatingData.to_csv('bulletMidRatingData.csv')\n",
    "bulletHighRatingData.to_csv('bulletHighingData.csv')\n",
    "\n",
    "rapidLowRatingData.to_csv('rapidLowRatingData.csv')\n",
    "rapidMidRatingData.to_csv('rapidMidRatingData.csv')\n",
    "rapidHighRatingData.to_csv('rapidHighingData.csv')\n",
    "\n",
    "classicalLowRatingData.to_csv('classicalLowRatingData.csv')\n",
    "classicalMidRatingData.to_csv('classicalMidRatingData.csv')\n",
    "classicalHighRatingData.to_csv('classicalHighingData.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We move first to blitz mid rating, as it is our largest dataset, and may require more steps including random sampling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
